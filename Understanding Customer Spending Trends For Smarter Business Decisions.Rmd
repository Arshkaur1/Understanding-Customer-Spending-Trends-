---
title: "UNDERSTANDING CUSTOMER SPENDING TRENDS FOR SMARTER BUSINESS DECISIONS"
author: "Arshdeep Kaur"
date: "2025-04-10"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



### CLEANING ###



```{r}
# Load necessary libraries
library(dplyr)
library(readr)
library(stringr)

# Step 1: Load the dataset
data <- read_csv("Customer Shopping Trends.csv")

# Step 2: Check structure and summary
str(data)
summary(data)

# Step 3: Remove duplicate rows
data <- data %>% distinct()

# Step 4: Check for missing values
colSums(is.na(data))

# Step 5: Clean and standardize categorical variables
# Trim whitespace and convert to lowercase (example for Gender, Season)
data$Gender <- str_to_title(str_trim(data$Gender))
data$Season <- str_to_title(str_trim(data$Season))
data$`Subscription Status` <- str_to_title(str_trim(data$`Subscription Status`))

# Step 6: Convert columns to appropriate types
data$`Purchase Amount (USD)` <- as.numeric(data$`Purchase Amount (USD)`)
data$`Review Rating` <- as.numeric(data$`Review Rating`)
data$`Previous Purchases` <- as.integer(data$`Previous Purchases`)

# View cleaned data
head(data)

```




### EXPLORATORY DATA ANALYSIS ###




```{r}
# Load libraries
library(dplyr)
library(ggplot2)
library(ggcorrplot)
library(stringr)

# Rename column for easier access
data <- data %>%
  rename(Purchase_Amount = `Purchase Amount (USD)`)

# --- Gender vs Average Purchase Amount ---
data %>%
  group_by(Gender) %>%
  summarise(Avg_Purchase = mean(Purchase_Amount, na.rm = TRUE)) %>%
  ggplot(aes(x = Gender, y = Avg_Purchase, fill = Gender)) +
  geom_col() +
  labs(title = "Average Purchase Amount by Gender", y = "Avg Purchase ($)") +
  theme_minimal()


# --- Subscription Status vs Previous Purchases ---
data %>%
  group_by(`Subscription Status`) %>%
  summarise(Avg_Previous_Purchases = mean(`Previous Purchases`, na.rm = TRUE)) %>%
  ggplot(aes(x = `Subscription Status`, y = Avg_Previous_Purchases, fill = `Subscription Status`)) +
  geom_col() +
  labs(title = "Average Past Purchases by Subscription Status") +
  theme_minimal()

# --- Impact of Discounts on Purchase Amount ---
data %>%
  group_by(`Discount Applied`) %>%
  summarise(Avg_Purchase = mean(Purchase_Amount, na.rm = TRUE)) %>%
  ggplot(aes(x = `Discount Applied`, y = Avg_Purchase, fill = `Discount Applied`)) +
  geom_col() +
  labs(title = "Impact of Discount Application on Purchase Amount") +
  theme_minimal()

# --- Most Common Shipping Types ---
data %>%
  count(`Shipping Type`) %>%
  ggplot(aes(x = reorder(`Shipping Type`, n), y = n, fill = `Shipping Type`)) +
  geom_col() +
  coord_flip() +
  labs(title = "Shipping Type Popularity", x = "Shipping Type", y = "Count") +
  theme_minimal()

# --- Frequency of Purchases by Age Group ---
data$Age_Group <- cut(data$Age,
                      breaks = c(18, 25, 35, 45, 55, 75),
                      labels = c("18-25", "26-35", "36-45", "46-55", "56-75"),
                      include.lowest = TRUE)

data %>%
  group_by(Age_Group, `Frequency of Purchases`) %>%
  summarise(Count = n()) %>%
  ggplot(aes(x = Age_Group, y = Count, fill = `Frequency of Purchases`)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Purchase Frequency by Age Group", y = "Number of Customers") +
  theme_minimal()

# --- Correlation Matrix of Numeric Fields ---
numeric_data <- data %>% select_if(is.numeric)
corr_matrix <- cor(numeric_data, use = "complete.obs")
ggcorrplot(corr_matrix, lab = TRUE)

# --- Sales by Season and Category ---
data %>%
  group_by(Season, Category) %>%
  summarise(Total_Sales = sum(Purchase_Amount, na.rm = TRUE)) %>%
  ggplot(aes(x = Season, y = Total_Sales, fill = Category)) +
  geom_col(position = "dodge") +
  labs(title = "Seasonal Sales by Product Category", y = "Total Sales") +
  theme_minimal()

# --- Purchase Amount by Product Category ---
data %>%
  group_by(Category) %>%
  summarise(Avg_Purchase = mean(Purchase_Amount, na.rm = TRUE)) %>%
  ggplot(aes(x = reorder(Category, Avg_Purchase), y = Avg_Purchase, fill = Category)) +
  geom_col() +
  coord_flip() +
  labs(title = "Average Purchase by Product Category") +
  theme_minimal()

# --- Purchase Amount by Season ---
data %>%
  group_by(Season) %>%
  summarise(Avg_Purchase = mean(Purchase_Amount, na.rm = TRUE)) %>%
  ggplot(aes(x = Season, y = Avg_Purchase, fill = Season)) +
  geom_col() +
  labs(title = "Average Purchase by Season") +
  theme_minimal()

```



1. Average Purchase Amount by Gender
Observation: The average purchase amount by female customers is slightly higher than that of male customers.
Interpretation: While both genders spend almost equally, small behavioral differences might be leveraged in personalized marketing strategies.

2. Average Previous Purchases by Subscription Status
Observation: Customers with an active subscription ("Yes") have a higher average of previous purchases than unsubscribed ones.
Interpretation: Subscription is clearly linked to customer loyalty or repeat purchases. Considering to invest in strategies that encourage users to subscribe is a good strategy.

3. Discount Applied vs Purchase Amount
Observation: Customers who received no discount spent slightly more on average than those who got a discount.
Interpretation: Discounts may attract buyers but don't necessarily increase individual spending. This could suggest budget-conscious buyers using discounts.

4. Shipping Type Popularity
Observation: All shipping types are fairly balanced, with Free Shipping being slightly more preferred.
Interpretation: Providing free shipping might increase competitiveness, but there's evident customer acceptance for varied delivery options.

5. Purchase Frequency by Age Group
Observation:
Older age groups (46–75) tend to shop more frequently across all frequencies.
Younger customers (18–25) appear less engaged across all frequencies.
Interpretation: Older customers might have more stable shopping habits or disposable income. Younger demographics might require more engagement or incentives.

6. Correlation Heatmap
Observation:
Very weak correlations between Purchase_Amount and all other numeric variables.
Interpretation: No strong linear relationships between variables.

7. Seasonal Sales by Product Category
Observation:
Clothing dominates sales in all seasons.
Accessories perform second-best and spike during Fall and Summer.
Footwear and Outerwear contribute less but stay relatively steady.
Interpretation: This insight is useful for seasonal inventory planning. For example, stock more clothing across the year, push accessories in Fall/Summer.







### QUESTION 1: What factors influence the amount a customer spends in a single transaction? ###


```{r}
# Convert relevant categorical variables to factors
data$Gender <- as.factor(data$Gender)
data$`Subscription Status` <- as.factor(data$`Subscription Status`)
data$`Discount Applied` <- as.factor(data$`Discount Applied`)
data$`Promo Code Used` <- as.factor(data$`Promo Code Used`)
data$Category <- as.factor(data$Category)
data$Season <- as.factor(data$Season)
data$`Payment Method` <- as.factor(data$`Payment Method`)
data$`Shipping Type` <- as.factor(data$`Shipping Type`)

# Linear regression model
model <- lm(Purchase_Amount ~ Gender + Age + `Review Rating` + 
              `Subscription Status` + `Discount Applied` + Category + 
              `Payment Method` + Season, 
            data = data)

summary(model)

```


Model Fit
R-squared = 0.0078, Only 0.78% of the variance in purchase amount is explained by the model.
Adjusted R-squared = 0.0037, Even lower when adjusting for number of variables.

What this means:
Model fit is very low. That means: Purchase behavior is likely influenced by unobserved factors (like income, lifestyle, marketing exposure) or, the relationships may not be linear — perhaps a decision tree or random forest model could find better patterns.

Seasonality has a real influence – customers spend less in Spring and Summer.
Review ratings, payment type (Venmo, Credit Card), and category (Outerwear) show some influence, but are not strongly significant.
Discounts, subscriptions, gender, and age did not have a measurable impact on purchase amount in this model.




```{r}
# Install if not already
# install.packages("rpart")
# install.packages("randomForest")
# install.packages("rpart.plot")

library(rpart)
library(rpart.plot)
library(dplyr)

# Build Decision Tree model
tree_model <- rpart(Purchase_Amount ~ Gender + Age + `Review Rating` + 
                      `Subscription Status` + `Discount Applied` +
                      Category + `Payment Method` + Season + 
                      `Shipping Type` + `Promo Code Used`,
                    data = data, method = "anova", control = rpart.control(cp = 0.001))

rpart.plot(tree_model, type = 2, extra = 101)
summary(tree_model)



```

What this means:
Age is the most important variable — meaning older/younger customers tend to show different purchase behaviors.
Review Rating has strong influence — possibly reflects satisfaction or trust leading to bigger spends.
Shipping Type and Payment Method matter more than discounts or gender.
Season and Category also play significant but slightly lesser roles.


Interpretations for Question 1:
To explore the factors that influence how much a customer spends in a single transaction, we began by fitting a linear regression model using demographic and behavioral features such as Age, Gender, Review Rating, Subscription Status, Discount Applied, Category, Payment Method, and Season. The model revealed that seasonality had the most consistent influence, with customers spending significantly less during spring and summer. Other variables such as Review Rating, Payment Method (Venmo, Credit Card), and the Outerwear product category showed marginal effects. However, the model's overall fit was weak (R² = 0.0078), suggesting that linear relationships are insufficient to capture the complexity of customer spending behavior.

To address this, we applied a decision tree regression model, which revealed more nuanced, non-linear patterns. In the tree, Age emerged as the most influential variable, followed by Review Rating, Shipping Type, and Payment Method. Surprisingly, Discount Applied, Subscription Status, and Gender had minimal predictive power in both models. This analysis indicates that spending behavior is likely driven by more complex interactions between variables and may be better captured using tree-based models.



### QUESTION 2: Can we identify patterns in repeat purchases based on customer demographics and shopping preferences? ### 



```{r}
# Define repeat customer: 1 if Previous Purchases > 1, else 0
data$Repeat_Customer <- ifelse(data$`Previous Purchases` > 1, 1, 0)
data$Repeat_Customer <- as.factor(data$Repeat_Customer)

# Check class distribution
table(data$Repeat_Customer)

```


```{r}

# Encode target as factor (just to be safe)
data$Repeat_Customer <- as.factor(data$Repeat_Customer)

# Split data (80% train / 20% test)
set.seed(123)
library(caret)

split <- createDataPartition(data$Repeat_Customer, p = 0.8, list = FALSE)
train <- data[split, ]
test <- data[-split, ]


library(class)

# Prepare numeric matrix (KNN needs numeric data only!)
train_knn <- train
test_knn <- test

# One-hot encode categorical features
train_knn <- model.matrix(Repeat_Customer ~ . -1, data = train_knn)
test_knn <- model.matrix(Repeat_Customer ~ . -1, data = test_knn)

# Separate features and target
train_x <- train_knn
test_x <- test_knn
train_y <- train$Repeat_Customer

# Step 1: Create the same formula and model on training data
formula_knn <- Repeat_Customer ~ Gender + Age + `Review Rating` + 
                `Subscription Status` + `Discount Applied` +
                Category + `Payment Method` + Season + 
                `Shipping Type` + `Promo Code Used` + `Purchase_Amount`

# Step 2: Create model matrix from training data
train_matrix <- model.matrix(formula_knn, data = train)[, -1]  # Remove intercept
test_matrix <- model.matrix(formula_knn, data = test)[, -1]    # Must match columns

# Step 3: Prepare target variable
train_target <- train$Repeat_Customer
test_target <- test$Repeat_Customer


# Ensure all matrices are numeric
pred_knn <- knn(train = train_matrix, test = test_matrix, cl = train_target, k = 5)

# Confusion matrix
confusionMatrix(pred_knn, test_target)



```

What This Means:
The model predicts everyone as class 1 (non-repeat customer).
Accuracy is 97.95%, which looks amazing at first — but it's deceptive.
Kappa = 0 → Model has no predictive power beyond majority class guessing.
Sensitivity = 0 → The model completely failed to identify any repeat customers.
Pos Pred Value = NaN → Because no samples were predicted as class 0 at all.




```{r}
# BALANCING DATA

library(dplyr)

# Separate classes
minority <- filter(data, Repeat_Customer == 0)
majority <- filter(data, Repeat_Customer == 1)

# Upsample minority class to match majority
set.seed(123)
minority_upsampled <- sample_n(minority, size = nrow(majority), replace = TRUE)

# Combine balanced dataset
data_balanced <- bind_rows(minority_upsampled, majority)

# Check class balance
table(data_balanced$Repeat_Customer)


# Required library
library(e1071)

# Split balanced dataset (if not already done)
set.seed(123)
split <- createDataPartition(data_balanced$Repeat_Customer, p = 0.8, list = FALSE)
train <- data_balanced[split, ]
test <- data_balanced[-split, ]


svm_model <- svm(Repeat_Customer ~ Gender + Age + `Review Rating` + 
                   `Subscription Status` + `Discount Applied` +
                   Category + `Payment Method` + Season + 
                   `Shipping Type` + `Promo Code Used` + `Purchase_Amount`,
                 data = train, 
                 kernel = "radial",   # Try "linear" or "polynomial" if you'd like
                 probability = TRUE)

# Predict classes
pred_svm <- predict(svm_model, test)

# Evaluate model
library(caret)
confusionMatrix(pred_svm, test$Repeat_Customer)

```

What This Means:
Total predictions: 1526
Correct: 763 (class 0) + 656 (class 1) = 1419
Accuracy: 92.99%
Balanced Accuracy: 92.99%
Kappa: 0.8598, indicating strong agreement beyond chance

SVM model significantly outperforms KNN (which hovered at 50% accuracy).
We are now effectively identifying repeat customers with high reliability.

Interpretations for Question 2:

To explore patterns in customer loyalty, we modeled repeat purchase behavior using customer demographics and shopping preferences. Customers were classified as repeat buyers if they had made more than one prior purchase. Initially, a K-Nearest Neighbors (KNN) classifier was trained on the original dataset, but it failed to identify any repeat customers due to severe class imbalance — predicting only the majority class and resulting in a misleadingly high accuracy of 97.9%, but a Kappa of 0, indicating no actual predictive value.

To address this, we applied data balancing through upsampling of the minority class. With a balanced dataset, we then trained a Support Vector Machine (SVM) model using a radial kernel. The SVM achieved an accuracy of 92.99% with a balanced accuracy of 92.99% and a Kappa of 0.8598, indicating strong predictive power and high agreement beyond chance. These results suggest that customer demographics and shopping preferences indeed hold substantial predictive power for identifying repeat buyers. This analysis demonstrates that with appropriate preprocessing and model selection, we can reliably distinguish repeat customers — establishing a solid foundation for developing loyalty prediction tools and targeted retention strategies.



### QUESTION 3: Can we predict if a customer will subscribe based on their purchase behavior? ### 



```{r}
library(caret)
set.seed(123)

split <- createDataPartition(data$`Subscription Status`, p = 0.8, list = FALSE)
train <- data[split, ]
test <- data[-split, ]


# Full model
full_model <- glm(`Subscription Status` ~ Age + Gender + `Review Rating` + 
                    Category + Season + Purchase_Amount +
                    `Previous Purchases` + `Frequency of Purchases` +
                    `Discount Applied` + `Promo Code Used` +
                    `Shipping Type` + `Payment Method`,
                  data = train, family = "binomial")

# Stepwise model selection
step_model <- step(full_model, direction = "both")

# View final model summary
summary(step_model)


# Predict probabilities
pred_probs <- predict(full_model, newdata = test, type = "response")

# Convert to predicted class
pred_class <- ifelse(pred_probs > 0.5, "Yes", "No")
pred_class <- as.factor(pred_class)

# Confusion matrix
confusionMatrix(pred_class, test$`Subscription Status`)


```

What this Means:
The model is very confident and correct when it predicts a subscriber (Yes).
It does well overall, but is slightly weaker at catching all non-subscribers (sensitivity for class “No”).
Excellent precision for "Yes" class — this means if you want to target likely subscribers, this model is great for it!



Interpretations for Question 3:
To predict whether a customer will subscribe, we developed a logistic regression model using a comprehensive set of demographic and behavioral features, including Age, Gender, Purchase Amount, Review Rating, Previous Purchases, Discount Applied, Shipping Type, Promo Code Used, and others. We applied stepwise model selection to reduce complexity and retain only the most impactful predictors. The final model achieved a strong overall performance, with an accuracy of 82.7%, balanced accuracy of 86.5%, and a Kappa score of 0.62, indicating good predictive power beyond chance.

The model showed that customers who opted for express shipping were significantly more likely to subscribe, while those shopping during the winter season were less likely to do so. Surprisingly, features such as Discount Applied and Promo Code Used had minimal influence on subscription decisions. These findings highlight the importance of convenience and seasonal behavior in driving subscription likelihood, offering a valuable foundation for targeted retention strategies and personalized subscription campaigns.




### QUESTION 4: Can we cluster customers based on shopping behavior to identify personas? ### 


```{r}
cluster_data <- data %>%
  select(Age, `Review Rating`, Purchase_Amount, `Previous Purchases`) %>%
  na.omit()  # Remove missing values

scaled_data <- scale(cluster_data)

wss <- vector()

# Try 1 to 10 clusters
for (k in 1:10) {
  km_out <- kmeans(scaled_data, centers = k, nstart = 25)
  wss[k] <- km_out$tot.withinss
}

# Plot elbow curve
plot(1:10, wss, type = "b", pch = 19,
     xlab = "Number of Clusters",
     ylab = "Total Within-Cluster Sum of Squares",
     main = "Elbow Method for Choosing K")

set.seed(123)

kmeans_model <- kmeans(scaled_data, centers = 3, nstart = 25)  # Try K = 3 (or your choice)

# Add cluster labels to data
cluster_data$Cluster <- as.factor(kmeans_model$cluster)



ggplot(cluster_data, aes(x = Purchase_Amount, y = `Previous Purchases`, color = Cluster)) +
  geom_point(alpha = 0.7) +
  labs(title = "Customer Clusters by Spend and Loyalty",
       x = "Purchase Amount", y = "Previous Purchases") +
  theme_minimal()


# Select relevant numeric features for PCA
pca_data <- data %>%
  select(Age, `Review Rating`, Purchase_Amount, `Previous Purchases`) %>%
  na.omit()

# Scale the data
scaled_pca <- scale(pca_data)

pca_result <- prcomp(scaled_pca, center = TRUE, scale. = TRUE)
summary(pca_result)  # See how much variance is explained

# Use first 2 principal components
pca_df <- as.data.frame(pca_result$x[, 1:3])
pca_df$Cluster <- cluster_data$Cluster  # Assuming cluster_data already has Cluster column

library(plotly)
# Create 3D plot
plot_ly(data = pca_df, 
        x = ~PC1, 
        y = ~PC2, 
        z = ~PC3, 
        color = ~Cluster,
        colors = c("red", "green", "blue"),
        type = "scatter3d", 
        mode = "markers") %>%
  add_markers() %>%
  layout(scene = list(
    xaxis = list(title = "PC1"),
    yaxis = list(title = "PC2"),
    zaxis = list(title = "PC3")
  ),
  title = list(text = "3D PCA: Customer Clusters"))

```



Interpretations for Question 4:
To uncover meaningful customer segments, we applied K-Means clustering on four key behavioral features: Age, Review Rating, Purchase Amount (USD), and Previous Purchases. The algorithm grouped customers into three distinct clusters, each representing a unique persona based on purchasing behavior and engagement. To visualize and validate these clusters, we used Principal Component Analysis (PCA) to reduce the data’s dimensionality. While the first two principal components captured approximately 52% of the total variance, incorporating the third component increased that coverage to 76%, providing a much clearer separation between segments. The resulting 3D PCA plot confirmed distinct boundaries among the clusters, revealing more nuanced patterns in customer behavior that were less visible in two dimensions.

Based on this analysis, we identified three customer personas:
1. New or Budget Shoppers – lower spend and fewer purchases
2. Loyal Mid-Spenders – frequent purchasers with moderate spending
3. High-Value Customers – fewer transactions but higher average spend

These insights provide a strong foundation for targeted marketing strategies, personalized offers, and customer retention campaigns tailored to the unique needs and behaviors of each segment.







